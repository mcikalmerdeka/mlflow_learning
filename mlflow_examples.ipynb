{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# MLflow Tutorial: Hands-on Examples\n",
        "\n",
        "This notebook provides practical examples of MLflow usage for data science MLOps. Also include the testing for tracking LLM application.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Make sure you have installed the dependencies using UV:\n",
        "```bash\n",
        "uv add mlflow scikit-learn pandas numpy matplotlib seaborn dotenv ipykernel\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup and Basic Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLflow tracking URI: file:./mlruns\n",
            "MLflow version: 3.1.4\n"
          ]
        }
      ],
      "source": [
        "# Importing Libraries\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import mlflow.models\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# # Classical ML Libraries\n",
        "# from sklearn.datasets import load_iris, load_wine\n",
        "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# LLM Libraries\n",
        "import openai\n",
        "\n",
        "# Configure MLflow for tracking classical ML models\n",
        "tracking_uri = \"file:./mlruns\"\n",
        "mlflow.set_tracking_uri(tracking_uri)\n",
        "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
        "print(f\"MLflow version: {mlflow.__version__}\")\n",
        "\n",
        "# Configure MLflow for tracking LLM models\n",
        "tracking_uri = \"file:./llm_runs\"\n",
        "mlflow.set_tracking_uri(tracking_uri)\n",
        "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
        "print(f\"MLflow version: {mlflow.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classical ML Tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 1. Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iris dataset: (150, 4), classes: 3\n",
            "Wine dataset: (178, 13), classes: 3\n"
          ]
        }
      ],
      "source": [
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X_iris, y_iris = iris.data, iris.target\n",
        "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
        "    X_iris, y_iris, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Load Wine dataset for additional examples\n",
        "wine = load_wine()\n",
        "X_wine, y_wine = wine.data, wine.target\n",
        "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(\n",
        "    X_wine, y_wine, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Iris dataset: {X_iris.shape}, classes: {len(np.unique(y_iris))}\")\n",
        "print(f\"Wine dataset: {X_wine.shape}, classes: {len(np.unique(y_wine))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 2. Basic MLflow Tracking\n",
        "\n",
        "This section includes:\n",
        "\n",
        "- Creating an experiment\n",
        "\n",
        "- Creating a run\n",
        "    - Single run\n",
        "    - Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Using existing experiment: iris-classification-tutorial (ID: 623039503078250544)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='file:///e:/mlflow_testing/mlruns/623039503078250544', creation_time=1753396716576, experiment_id='623039503078250544', last_update_time=1753396716576, lifecycle_stage='active', name='iris-classification-tutorial', tags={}>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create experiment\n",
        "experiment_name = \"iris-classification-tutorial\"\n",
        "try:\n",
        "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "    if experiment is None:\n",
        "        experiment_id = mlflow.create_experiment(experiment_name)\n",
        "        print(f\"✅ Created new experiment: {experiment_name} (ID: {experiment_id})\")\n",
        "    else:\n",
        "        experiment_id = experiment.experiment_id\n",
        "        print(f\"✅ Using existing experiment: {experiment_name} (ID: {experiment_id})\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error creating experiment: {e}\")\n",
        "    \n",
        "    # Fallback: create with different approach\n",
        "    experiment_id = mlflow.create_experiment(experiment_name)\n",
        "\n",
        "# Set active experiment\n",
        "mlflow.set_experiment(experiment_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic tracking example - Single model run\n",
        "with mlflow.start_run(run_name=\"baseline-random-forest\"):\n",
        "    \n",
        "    # Single parameter values (not lists!)\n",
        "    n_estimators = 100\n",
        "    max_depth = 10\n",
        "    min_samples_split = 2\n",
        "    \n",
        "    # Log parameters\n",
        "    mlflow.log_param(\"model_type\", \"RandomForest\")\n",
        "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "    mlflow.log_param(\"max_depth\", max_depth)\n",
        "    mlflow.log_param(\"min_samples_split\", min_samples_split)\n",
        "    mlflow.log_param(\"dataset\", \"iris\")\n",
        "    mlflow.log_param(\"dataset_size\", len(X_train_iris))\n",
        "    \n",
        "    # Train model\n",
        "    start_time = time.perf_counter()\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train_iris, y_train_iris)\n",
        "    training_time = time.perf_counter() - start_time\n",
        "    \n",
        "    # Make predictions\n",
        "    y_pred_train = model.predict(X_train_iris)\n",
        "    y_pred_test = model.predict(X_test_iris)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    train_accuracy = accuracy_score(y_train_iris, y_pred_train)\n",
        "    test_accuracy = accuracy_score(y_test_iris, y_pred_test)\n",
        "    precision = precision_score(y_test_iris, y_pred_test, average='weighted')\n",
        "    recall = recall_score(y_test_iris, y_pred_test, average='weighted')\n",
        "    f1 = f1_score(y_test_iris, y_pred_test, average='weighted')\n",
        "    \n",
        "    # Log metrics\n",
        "    mlflow.log_metrics({\n",
        "        \"train_accuracy\": train_accuracy,\n",
        "        \"test_accuracy\": test_accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"training_time\": training_time\n",
        "    })\n",
        "    \n",
        "    # Log model with input example and signature (fixes warnings)\n",
        "    input_example = X_train_iris[:5]\n",
        "    mlflow.sklearn.log_model(\n",
        "        model, \n",
        "        \"model\",\n",
        "        input_example=input_example,\n",
        "        signature=mlflow.models.infer_signature(X_train_iris, y_pred_train)\n",
        "    )\n",
        "    \n",
        "    # Save and log confusion matrix\n",
        "    cm = confusion_matrix(y_test_iris, y_pred_test)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix - Random Forest')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig('confusion_matrix_rf.png', dpi=150, bbox_inches='tight')\n",
        "    mlflow.log_artifact('confusion_matrix_rf.png')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"Training time: {training_time:.2f} seconds\")\n",
        "    print(f\"Run ID: {mlflow.active_run().info.run_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Option 1: Manual Nested Runs (Educational)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HYPERPARAMETER TUNING WITH NESTED RUNS - BEST PRACTICE\n",
        "import itertools\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [5, 10],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = None\n",
        "best_model = None\n",
        "\n",
        "# Parent run for the entire tuning experiment\n",
        "with mlflow.start_run(run_name=\"hyperparameter-tuning-experiment\") as parent_run:\n",
        "    \n",
        "    # Log experiment metadata\n",
        "    mlflow.log_param(\"tuning_strategy\", \"grid_search\")\n",
        "    mlflow.log_param(\"param_space\", str(param_grid))\n",
        "    mlflow.log_param(\"total_combinations\", len(list(itertools.product(*param_grid.values()))))\n",
        "    \n",
        "    run_count = 0\n",
        "    \n",
        "    # Grid search with nested runs\n",
        "    for n_est in param_grid['n_estimators']:\n",
        "        for depth in param_grid['max_depth']:\n",
        "            for min_split in param_grid['min_samples_split']:\n",
        "                \n",
        "                run_count += 1\n",
        "                \n",
        "                # Child run for each parameter combination\n",
        "                with mlflow.start_run(run_name=f\"run_{run_count:02d}\", nested=True) as child_run:\n",
        "                    \n",
        "                    # Current parameter combination\n",
        "                    current_params = {\n",
        "                        \"n_estimators\": n_est,\n",
        "                        \"max_depth\": depth,\n",
        "                        \"min_samples_split\": min_split\n",
        "                    }\n",
        "                    \n",
        "                    # Log parameters\n",
        "                    mlflow.log_params({\n",
        "                        **current_params,\n",
        "                        \"model_type\": \"RandomForest\",\n",
        "                        \"dataset\": \"iris\",\n",
        "                        \"random_state\": 42\n",
        "                    })\n",
        "                    \n",
        "                    # Train model\n",
        "                    start_time = time.perf_counter()\n",
        "                    model = RandomForestClassifier(\n",
        "                        n_estimators=n_est,\n",
        "                        max_depth=depth,\n",
        "                        min_samples_split=min_split,\n",
        "                        random_state=42\n",
        "                    )\n",
        "                    model.fit(X_train_iris, y_train_iris)\n",
        "                    training_time = time.perf_counter() - start_time\n",
        "                    \n",
        "                    # Make predictions\n",
        "                    y_pred_train = model.predict(X_train_iris)\n",
        "                    y_pred_test = model.predict(X_test_iris)\n",
        "                    \n",
        "                    # Calculate metrics\n",
        "                    train_accuracy = accuracy_score(y_train_iris, y_pred_train)\n",
        "                    test_accuracy = accuracy_score(y_test_iris, y_pred_test)\n",
        "                    precision = precision_score(y_test_iris, y_pred_test, average='weighted')\n",
        "                    recall = recall_score(y_test_iris, y_pred_test, average='weighted')\n",
        "                    f1 = f1_score(y_test_iris, y_pred_test, average='weighted')\n",
        "                    \n",
        "                    # Log metrics\n",
        "                    mlflow.log_metrics({\n",
        "                        \"train_accuracy\": train_accuracy,\n",
        "                        \"test_accuracy\": test_accuracy,\n",
        "                        \"precision\": precision,\n",
        "                        \"recall\": recall,\n",
        "                        \"f1_score\": f1,\n",
        "                        \"training_time\": training_time\n",
        "                    })\n",
        "                    \n",
        "                    # Log model with signature (always include for best practices)\n",
        "                    input_example = X_train_iris[:3]\n",
        "                    mlflow.sklearn.log_model(\n",
        "                        model, \n",
        "                        \"model\",\n",
        "                        input_example=input_example,\n",
        "                        signature=mlflow.models.infer_signature(X_train_iris, y_pred_test)\n",
        "                    )\n",
        "                    \n",
        "                    # Track best model\n",
        "                    if test_accuracy > best_accuracy:\n",
        "                        best_accuracy = test_accuracy\n",
        "                        best_params = current_params.copy()\n",
        "                        best_model = model\n",
        "                    \n",
        "                    print(f\"Run {run_count:2d} | n_est={n_est:3d}, depth={depth:2d}, min_split={min_split:2d} | Accuracy: {test_accuracy:.4f}\")\n",
        "    \n",
        "    # Log best results to parent run\n",
        "    mlflow.log_params({f\"best_{k}\": v for k, v in best_params.items()})\n",
        "    mlflow.log_metric(\"best_test_accuracy\", best_accuracy)\n",
        "    mlflow.log_metric(\"total_runs\", run_count)\n",
        "    \n",
        "    # Register best model\n",
        "    if best_model is not None:\n",
        "        input_example = X_train_iris[:5]\n",
        "        mlflow.sklearn.log_model(\n",
        "            best_model,\n",
        "            \"best_model\", \n",
        "            input_example=input_example,\n",
        "            signature=mlflow.models.infer_signature(X_train_iris, best_model.predict(X_test_iris)),\n",
        "            registered_model_name=\"iris_best_rf_tuned\"\n",
        "        )\n",
        "    \n",
        "    print(f\"\\n🎯 TUNING COMPLETE!\")\n",
        "    print(f\"📊 Tested {run_count} parameter combinations\")\n",
        "    print(f\"🏆 Best accuracy: {best_accuracy:.4f}\")\n",
        "    print(f\"⚙️  Best parameters: {best_params}\")\n",
        "    print(f\"🔄 Parent run ID: {parent_run.info.run_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "#### Option 2: Using GridSearchCV with MLflow Autologging (Recommended for Hyperparameter Tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/07/25 16:32:10 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 1.3.0 <= scikit-learn <= 1.7.0, but the installed version is 1.7.1. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Running GridSearchCV with 3-fold CV...\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/07/25 16:32:32 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
            "2025/07/25 16:32:35 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
            "2025/07/25 16:32:35 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏆 GRIDSEARCH COMPLETE!\n",
            "📊 Best CV score: 0.9583\n",
            "🎯 Holdout test accuracy: 1.0000\n",
            "⚙️  Best parameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "🤖 All runs auto-logged to MLflow!\n"
          ]
        }
      ],
      "source": [
        "# OPTION 2: GridSearchCV with MLflow Autologging - EVEN EASIER!\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Enable autologging for sklearn (captures GridSearchCV automatically)\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid_cv = {\n",
        "    'n_estimators': [50, 75],\n",
        "    'max_depth': [5, 10],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# Create experiment for GridSearchCV\n",
        "mlflow.set_experiment(\"iris-gridsearch-autolog\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"gridsearch-with-autolog-2\") as run:\n",
        "    \n",
        "    # Create base model\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "    \n",
        "    # Create GridSearchCV\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=rf,\n",
        "        param_grid=param_grid_cv,\n",
        "        cv=3,  # 3-fold cross-validation\n",
        "        scoring='accuracy', # set scoring to accuracy\n",
        "        n_jobs=-1,  # Use all cores\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    print(\"🔍 Running GridSearchCV with 3-fold CV...\")\n",
        "    \n",
        "    # Fit - this will automatically log everything to MLflow!\n",
        "    grid_search.fit(X_train_iris, y_train_iris)\n",
        "    \n",
        "    # Get best results\n",
        "    best_model = grid_search.best_estimator_\n",
        "    best_params = grid_search.best_params_\n",
        "    best_score = grid_search.best_score_\n",
        "    \n",
        "    # Test on holdout set\n",
        "    test_accuracy = best_model.score(X_test_iris, y_test_iris)\n",
        "    \n",
        "    # Log additional custom metrics\n",
        "    mlflow.log_metric(\"holdout_test_accuracy\", test_accuracy)\n",
        "    mlflow.log_param(\"cv_folds\", 5)\n",
        "    mlflow.log_param(\"total_combinations_tested\", len(grid_search.cv_results_['mean_test_score']))\n",
        "    \n",
        "    print(f\"\\n🏆 GRIDSEARCH COMPLETE!\")\n",
        "    print(f\"📊 Best CV score: {best_score:.4f}\")\n",
        "    print(f\"🎯 Holdout test accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"⚙️  Best parameters: {best_params}\")\n",
        "    print(f\"🤖 All runs auto-logged to MLflow!\")\n",
        "\n",
        "# Disable autologging\n",
        "mlflow.sklearn.autolog(disable=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "#### Option 3: RandomizedSearchCV for Large Parameter Spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPTION 3: RandomizedSearchCV for large parameter spaces\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Enable autologging again\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "# Define LARGE parameter space with distributions\n",
        "param_distributions = {\n",
        "    'n_estimators': randint(50, 300),  # Random integers between 50-300\n",
        "    'max_depth': randint(3, 20),       # Random integers between 3-20\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'max_features': uniform(0.1, 0.8)  # Random float between 0.1-0.9\n",
        "}\n",
        "\n",
        "# Set experiment\n",
        "mlflow.set_experiment(\"iris-randomized-search\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"randomized-search-efficient\") as run:\n",
        "    \n",
        "    # Create base model\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "    \n",
        "    # Create RandomizedSearchCV - only test 20 random combinations\n",
        "    random_search = RandomizedSearchCV(\n",
        "        estimator=rf,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=20,  # Only test 20 random combinations (vs 100+ in full grid)\n",
        "        cv=3,       # 3-fold CV for speed\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    print(\"🎲 Running RandomizedSearchCV (20 random combinations)...\")\n",
        "    \n",
        "    # Fit - auto-logged to MLflow\n",
        "    random_search.fit(X_train_iris, y_train_iris)\n",
        "    \n",
        "    # Get results\n",
        "    best_model = random_search.best_estimator_\n",
        "    best_params = random_search.best_params_\n",
        "    best_score = random_search.best_score_\n",
        "    test_accuracy = best_model.score(X_test_iris, y_test_iris)\n",
        "    \n",
        "    # Log additional metrics\n",
        "    mlflow.log_metric(\"holdout_test_accuracy\", test_accuracy)\n",
        "    mlflow.log_param(\"search_type\", \"randomized\")\n",
        "    mlflow.log_param(\"n_iter\", 20)\n",
        "    \n",
        "    print(f\"\\n🎯 RANDOMIZED SEARCH COMPLETE!\")\n",
        "    print(f\"📊 Best CV score: {best_score:.4f}\")\n",
        "    print(f\"🎯 Holdout test accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"⚙️  Best parameters: {best_params}\")\n",
        "    print(f\"⚡ Much faster than full grid search!\")\n",
        "\n",
        "# Disable autologging\n",
        "mlflow.sklearn.autolog(disable=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "#### 🎯 Hyperparameter Tuning Summary: Choose Your Approach\n",
        "\n",
        "| **Method** | **When to Use** | **Pros** | **Cons** |\n",
        "|------------|-----------------|----------|----------|\n",
        "| **Manual Nested Runs** | Learning MLflow, custom logic needed | Full control, educational | More code, manual loops |\n",
        "| **GridSearchCV + Autolog** | Small parameter spaces, want all combinations | Easy, automatic logging | Can be slow for large grids |\n",
        "| **RandomizedSearchCV + Autolog** | Large parameter spaces, time constraints | Fast, good coverage, automatic | May miss optimal combination |\n",
        "\n",
        "#### 🏆 **Best Practices Recommendations:**\n",
        "\n",
        "1. **Start Simple**: Use GridSearchCV with autologging for most cases\n",
        "2. **Go Manual**: Use nested runs when you need custom experiment logic\n",
        "3. **Scale Up**: Use RandomizedSearchCV for large parameter spaces (>100 combinations)\n",
        "4. **Always Log**: Include `input_example` and `signature` in model logging\n",
        "5. **Track Best**: Use parent runs to summarize tuning experiments\n",
        "6. **Name Wisely**: Use descriptive run names and experiment names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 3. Compare Multiple Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare different models\n",
        "models_config = [\n",
        "    {\n",
        "        \"name\": \"logistic-regression\",\n",
        "        \"model\": LogisticRegression(random_state=42, max_iter=1000),\n",
        "        \"params\": {\"solver\": \"lbfgs\", \"max_iter\": 1000}\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"random-forest-small\",\n",
        "        \"model\": RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42),\n",
        "        \"params\": {\"n_estimators\": 50, \"max_depth\": 5}\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"random-forest-large\", \n",
        "        \"model\": RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42),\n",
        "        \"params\": {\"n_estimators\": 200, \"max_depth\": 15}\n",
        "    }\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "with mlflow.start_run(run_name=\"model-comparison\"):\n",
        "    for config in models_config:\n",
        "        with mlflow.start_run(run_name=config[\"name\"], nested=True):\n",
        "            # Log parameters\n",
        "            mlflow.log_param(\"model_type\", config[\"name\"])\n",
        "            mlflow.log_params(config[\"params\"])\n",
        "            \n",
        "            # Train model\n",
        "            start_time = time.time()\n",
        "            model = config[\"model\"]\n",
        "            model.fit(X_train_iris, y_train_iris)\n",
        "            training_time = time.time() - start_time\n",
        "            \n",
        "            # Evaluate\n",
        "            test_accuracy = accuracy_score(y_test_iris, model.predict(X_test_iris))\n",
        "            \n",
        "            # Log metrics\n",
        "            mlflow.log_metrics({\n",
        "                \"test_accuracy\": test_accuracy,\n",
        "                \"training_time\": training_time\n",
        "            })\n",
        "            \n",
        "            # Log model with input example and signature\n",
        "            input_example = X_train_iris[:3]\n",
        "            mlflow.sklearn.log_model(\n",
        "                model, \n",
        "                \"model\",\n",
        "                input_example=input_example,\n",
        "                signature=mlflow.models.infer_signature(X_train_iris, model.predict(X_test_iris))\n",
        "            )\n",
        "            \n",
        "            results.append({\n",
        "                \"model\": config[\"name\"],\n",
        "                \"accuracy\": test_accuracy,\n",
        "                \"training_time\": training_time\n",
        "            })\n",
        "            \n",
        "            print(f\"{config['name']}: {test_accuracy:.4f} accuracy, {training_time:.2f}s\")\n",
        "\n",
        "# Display results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nModel Comparison Results:\")\n",
        "print(results_df.sort_values('accuracy', ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 4. Hyperparameter Tuning with MLflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter tuning with nested runs\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [5, 10, 15, None]\n",
        "}\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = None\n",
        "\n",
        "with mlflow.start_run(run_name=\"hyperparameter-tuning\"):\n",
        "    mlflow.log_param(\"tuning_strategy\", \"grid_search\")\n",
        "    mlflow.log_param(\"param_space\", str(param_grid))\n",
        "    \n",
        "    for n_est in param_grid['n_estimators']:\n",
        "        for depth in param_grid['max_depth']:\n",
        "            with mlflow.start_run(nested=True):\n",
        "                # Log parameters\n",
        "                params = {\n",
        "                    \"n_estimators\": n_est,\n",
        "                    \"max_depth\": depth if depth is not None else \"None\"\n",
        "                }\n",
        "                mlflow.log_params(params)\n",
        "                \n",
        "                # Train model\n",
        "                model = RandomForestClassifier(\n",
        "                    n_estimators=n_est, \n",
        "                    max_depth=depth, \n",
        "                    random_state=42\n",
        "                )\n",
        "                model.fit(X_train_iris, y_train_iris)\n",
        "                \n",
        "                # Evaluate\n",
        "                accuracy = accuracy_score(y_test_iris, model.predict(X_test_iris))\n",
        "                mlflow.log_metric(\"test_accuracy\", accuracy)\n",
        "                \n",
        "                # Track best model\n",
        "                if accuracy > best_accuracy:\n",
        "                    best_accuracy = accuracy\n",
        "                    best_params = params.copy()\n",
        "                    # Log best model with signature\n",
        "                    input_example = X_train_iris[:3]\n",
        "                    mlflow.sklearn.log_model(\n",
        "                        model, \n",
        "                        \"model\",\n",
        "                        input_example=input_example,\n",
        "                        signature=mlflow.models.infer_signature(X_train_iris, model.predict(X_test_iris))\n",
        "                    )\n",
        "                \n",
        "                print(f\"n_est={n_est}, depth={depth}: {accuracy:.4f}\")\n",
        "    \n",
        "    # Log best results to parent run\n",
        "    mlflow.log_params({f\"best_{k}\": v for k, v in best_params.items()})\n",
        "    mlflow.log_metric(\"best_accuracy\", best_accuracy)\n",
        "\n",
        "print(f\"\\nBest accuracy: {best_accuracy:.4f}\")\n",
        "print(f\"Best parameters: {best_params}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 5. Model Registration and Versioning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train final model and register it\n",
        "with mlflow.start_run(run_name=\"production-model\"):\n",
        "    # Use best parameters from tuning\n",
        "    final_model = RandomForestClassifier(\n",
        "        n_estimators=100, \n",
        "        max_depth=10, \n",
        "        random_state=42\n",
        "    )\n",
        "    final_model.fit(X_train_iris, y_train_iris)\n",
        "    \n",
        "    # Evaluate\n",
        "    test_accuracy = accuracy_score(y_test_iris, final_model.predict(X_test_iris))\n",
        "    \n",
        "    # Log everything\n",
        "    mlflow.log_params({\n",
        "        \"n_estimators\": 100,\n",
        "        \"max_depth\": 10,\n",
        "        \"model_purpose\": \"production\"\n",
        "    })\n",
        "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
        "    \n",
        "    # Register model with signature and input example\n",
        "    input_example = X_train_iris[:5]\n",
        "    model_info = mlflow.sklearn.log_model(\n",
        "        final_model, \n",
        "        \"model\",\n",
        "        input_example=input_example,\n",
        "        signature=mlflow.models.infer_signature(X_train_iris, final_model.predict(X_test_iris)),\n",
        "        registered_model_name=\"iris_classifier\"\n",
        "    )\n",
        "    \n",
        "    print(f\"Model registered with accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"Model URI: {model_info.model_uri}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 6. Model Registry Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "client = MlflowClient()\n",
        "\n",
        "# List registered models\n",
        "registered_models = client.search_registered_models()\n",
        "print(\"Registered models:\")\n",
        "for model in registered_models:\n",
        "    print(f\"- {model.name}\")\n",
        "    for version in model.latest_versions:\n",
        "        print(f\"  Version {version.version}: {version.current_stage}\")\n",
        "\n",
        "# Get model details\n",
        "if registered_models:\n",
        "    model_name = \"iris_classifier\"\n",
        "    model_version = client.get_latest_versions(model_name)[0]\n",
        "    print(f\"\\nLatest version of {model_name}: {model_version.version}\")\n",
        "    \n",
        "    # Transition to staging\n",
        "    client.transition_model_version_stage(\n",
        "        name=model_name,\n",
        "        version=model_version.version,\n",
        "        stage=\"Staging\"\n",
        "    )\n",
        "    print(f\"Model {model_name} v{model_version.version} moved to Staging\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 7. Loading and Using Registered Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model from registry\n",
        "try:\n",
        "    # Load latest staging model\n",
        "    staging_model = mlflow.pyfunc.load_model(\"models:/iris_classifier/Staging\")\n",
        "    print(\"Loaded model from Staging\")\n",
        "    \n",
        "    # Make predictions\n",
        "    sample_data = X_test_iris[:5]\n",
        "    predictions = staging_model.predict(sample_data)\n",
        "    \n",
        "    print(\"\\nSample predictions:\")\n",
        "    for i, (sample, pred, actual) in enumerate(zip(sample_data, predictions, y_test_iris[:5])):\n",
        "        print(f\"Sample {i+1}: Predicted={pred}, Actual={actual}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    print(\"This might happen if no model is in Staging yet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 8. Advanced Features: Autologging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enable autologging\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "# Create new experiment for autologging\n",
        "mlflow.set_experiment(\"autologging-demo\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"autolog-example\"):\n",
        "    # Train model - everything is automatically logged!\n",
        "    auto_model = RandomForestClassifier(n_estimators=150, max_depth=12, random_state=42)\n",
        "    auto_model.fit(X_train_wine, y_train_wine)\n",
        "    \n",
        "    # Predictions are also logged\n",
        "    y_pred = auto_model.predict(X_test_wine)\n",
        "    accuracy = accuracy_score(y_test_wine, y_pred)\n",
        "    \n",
        "    print(f\"Autologged model accuracy on wine dataset: {accuracy:.4f}\")\n",
        "    print(\"Check MLflow UI to see all automatically logged parameters and metrics!\")\n",
        "\n",
        "# Disable autologging\n",
        "mlflow.sklearn.autolog(disable=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 9. Custom Artifacts and Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create experiment for custom artifacts\n",
        "mlflow.set_experiment(\"custom-artifacts-demo\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"custom-artifacts\"):\n",
        "    # Train model with preprocessing\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_wine)\n",
        "    X_test_scaled = scaler.transform(X_test_wine)\n",
        "    \n",
        "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "    model.fit(X_train_scaled, y_train_wine)\n",
        "    \n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test_wine, y_pred)\n",
        "    \n",
        "    # Log basic metrics\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_param(\"preprocessing\", \"StandardScaler\")\n",
        "    \n",
        "    # Save and log preprocessing artifacts\n",
        "    joblib.dump(scaler, \"scaler.pkl\")\n",
        "    mlflow.log_artifact(\"scaler.pkl\", \"preprocessing\")\n",
        "    \n",
        "    # Create feature importance plot\n",
        "    feature_names = wine.feature_names\n",
        "    if hasattr(model, 'coef_'):\n",
        "        importance = np.abs(model.coef_[0])\n",
        "        indices = np.argsort(importance)[::-1][:10]\n",
        "        \n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.title('Top 10 Feature Importance (Logistic Regression)')\n",
        "        plt.bar(range(10), importance[indices])\n",
        "        plt.xticks(range(10), [feature_names[i] for i in indices], rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')\n",
        "        mlflow.log_artifact('feature_importance.png', \"plots\")\n",
        "        plt.show()\n",
        "    \n",
        "    # Create classification report\n",
        "    from sklearn.metrics import classification_report\n",
        "    report = classification_report(y_test_wine, y_pred, target_names=wine.target_names)\n",
        "    \n",
        "    with open(\"classification_report.txt\", \"w\") as f:\n",
        "        f.write(report)\n",
        "    mlflow.log_artifact(\"classification_report.txt\", \"reports\")\n",
        "    \n",
        "    # Log model with signature and input example\n",
        "    input_example = X_train_scaled[:5]\n",
        "    mlflow.sklearn.log_model(\n",
        "        model, \n",
        "        \"model\",\n",
        "        input_example=input_example,\n",
        "        signature=mlflow.models.infer_signature(X_train_scaled, y_pred)\n",
        "    )\n",
        "    \n",
        "    print(f\"Wine classification accuracy: {accuracy:.4f}\")\n",
        "    print(\"Custom artifacts logged: scaler, feature importance plot, classification report\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 10. Experiment Analysis and Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Search and compare experiments\n",
        "from mlflow.entities import ViewType\n",
        "\n",
        "# Get all experiments\n",
        "experiments = client.search_experiments()\n",
        "print(\"Available experiments:\")\n",
        "for exp in experiments:\n",
        "    print(f\"- {exp.name} (ID: {exp.experiment_id})\")\n",
        "\n",
        "# Search runs from specific experiment\n",
        "iris_exp = mlflow.get_experiment_by_name(\"iris-classification-tutorial\")\n",
        "if iris_exp:\n",
        "    runs = client.search_runs(\n",
        "        experiment_ids=[iris_exp.experiment_id],\n",
        "        run_view_type=ViewType.ACTIVE_ONLY,\n",
        "        max_results=10\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nRuns in {iris_exp.name}:\")\n",
        "    for run in runs:\n",
        "        metrics = run.data.metrics\n",
        "        params = run.data.params\n",
        "        print(f\"Run: {run.info.run_name}\")\n",
        "        print(f\"  Accuracy: {metrics.get('test_accuracy', 'N/A')}\")\n",
        "        print(f\"  Model: {params.get('model_type', 'N/A')}\")\n",
        "        print(f\"  Status: {run.info.status}\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 11. Cleanup and Best Practices Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up temporary files\n",
        "import os\n",
        "temp_files = [\n",
        "    'confusion_matrix_rf.png', \n",
        "    'scaler.pkl', \n",
        "    'feature_importance.png',\n",
        "    'classification_report.txt'\n",
        "]\n",
        "\n",
        "for file in temp_files:\n",
        "    if os.path.exists(file):\n",
        "        os.remove(file)\n",
        "        print(f\"Removed {file}\")\n",
        "\n",
        "print(\"\\n=== MLflow Tutorial Complete ===\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Start MLflow UI: uv run mlflow ui\")\n",
        "print(\"2. Open http://localhost:5000 in your browser\")\n",
        "print(\"3. Explore your experiments, runs, and models!\")\n",
        "print(\"4. Try model serving: mlflow models serve -m 'models:/iris_classifier/Staging' -p 5001\")\n",
        "\n",
        "print(\"\\nKey takeaways:\")\n",
        "print(\"- Use experiments to organize related runs\")\n",
        "print(\"- Log parameters, metrics, and artifacts consistently\")\n",
        "print(\"- Use nested runs for hyperparameter tuning\")\n",
        "print(\"- Register important models for production use\")\n",
        "print(\"- Leverage autologging for quick experimentation\")\n",
        "print(\"- Save preprocessing artifacts for reproducibility\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LLM Application Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'SafeDumper' from 'yaml' (unknown location)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\MLflow Learning\\.venv\\Lib\\site-packages\\mlflow\\utils\\file_utils.py:59\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CSafeDumper \u001b[38;5;28;01mas\u001b[39;00m YamlSafeDumper\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
            "\u001b[31mImportError\u001b[39m: cannot import name 'CSafeDumper' from 'yaml' (unknown location)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Set up the environment\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      6\u001b[39m load_dotenv()\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\MLflow Learning\\.venv\\Lib\\site-packages\\mlflow\\__init__.py:44\u001b[39m\n\u001b[32m     41\u001b[39m     mlflow.mismatch._check_version_mismatch()\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m IS_TRACING_SDK_ONLY:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     45\u001b[39m         artifacts,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     46\u001b[39m         client,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     47\u001b[39m         config,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     48\u001b[39m         data,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     49\u001b[39m         exceptions,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     50\u001b[39m         genai,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     51\u001b[39m         models,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     52\u001b[39m         projects,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     53\u001b[39m         tracking,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     54\u001b[39m     )\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracing  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvironment_variables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MLFLOW_CONFIGURE_LOGGING\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\MLflow Learning\\.venv\\Lib\\site-packages\\mlflow\\artifacts\\__init__.py:14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MlflowException\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotos\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatabricks_pb2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BAD_REQUEST, INVALID_PARAMETER_VALUE\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _get_store\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracking\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01martifact_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     _download_artifact_from_uri,\n\u001b[32m     17\u001b[39m     _get_root_uri_and_artifact_path,\n\u001b[32m     18\u001b[39m     add_databricks_profile_info_to_artifact_uri,\n\u001b[32m     19\u001b[39m     get_artifact_repository,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload_artifacts\u001b[39m(\n\u001b[32m     24\u001b[39m     artifact_uri: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     25\u001b[39m     run_id: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     tracking_uri: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     29\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\MLflow Learning\\.venv\\Lib\\site-packages\\mlflow\\tracking\\__init__.py:9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThe ``mlflow.tracking`` module provides a Python CRUD interface to MLflow experiments\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mand runs. This is a lower level API that directly translates to MLflow\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m`REST API <../rest-api.html>`_ calls.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03mFor a higher level API for managing an \"active run\", use the :py:mod:`mlflow` module.\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Minimum APIs required for core tracing functionality of mlflow-tracing package.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracking\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tracking_service\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     _get_artifact_repo,\n\u001b[32m     11\u001b[39m     _get_store,\n\u001b[32m     12\u001b[39m     get_tracking_uri,\n\u001b[32m     13\u001b[39m     is_tracking_uri_set,\n\u001b[32m     14\u001b[39m     set_tracking_uri,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IS_TRACING_SDK_ONLY\n\u001b[32m     18\u001b[39m __all__ = [\n\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mget_tracking_uri\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mset_tracking_uri\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m_get_store\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m ]\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\MLflow Learning\\.venv\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Generator, Union\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvironment_variables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MLFLOW_TRACKING_URI\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdb_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DATABASE_ENGINES\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_LOCAL_FILE_AND_ARTIFACT_PATH\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracking\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrest_store\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RestStore\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\MLflow Learning\\.venv\\Lib\\site-packages\\mlflow\\store\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _unity_catalog  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01martifact\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m artifact_repo\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m abstract_store\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\MLflow Learning\\.venv\\Lib\\site-packages\\mlflow\\store\\_unity_catalog\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_unity_catalog\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m registry  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\MLflow Learning\\.venv\\Lib\\site-packages\\mlflow\\store\\_unity_catalog\\registry\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_unity_catalog\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     rest_store \u001b[38;5;28;01mas\u001b[39;00m rest_store,\n\u001b[32m      3\u001b[39m )\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_unity_catalog\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      5\u001b[39m     uc_oss_rest_store \u001b[38;5;28;01mas\u001b[39;00m uc_oss_rest_store,\n\u001b[32m      6\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\MLflow Learning\\.venv\\Lib\\site-packages\\mlflow\\store\\_unity_catalog\\registry\\rest_store.py:123\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_unity_catalog\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlineage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    114\u001b[39m     _DATABRICKS_LINEAGE_ID_HEADER,\n\u001b[32m    115\u001b[39m     _DATABRICKS_ORG_ID_HEADER,\n\u001b[32m    116\u001b[39m )\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_unity_catalog\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    118\u001b[39m     mlflow_tags_to_proto,\n\u001b[32m    119\u001b[39m     mlflow_tags_to_proto_version_tags,\n\u001b[32m    120\u001b[39m     proto_info_to_mlflow_prompt_info,\n\u001b[32m    121\u001b[39m     proto_to_mlflow_prompt,\n\u001b[32m    122\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01martifact\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatabricks_sdk_models_artifact_repo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    124\u001b[39m     DatabricksSDKModelsArtifactRepository,\n\u001b[32m    125\u001b[39m )\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01martifact\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpresigned_url_artifact_repo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    127\u001b[39m     PresignedUrlArtifactRepository,\n\u001b[32m    128\u001b[39m )\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mentities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpaged_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PagedList\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\MLflow Learning\\.venv\\Lib\\site-packages\\mlflow\\store\\artifact\\databricks_sdk_models_artifact_repo.py:8\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mentities\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileInfo\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvironment_variables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     MLFLOW_MULTIPART_DOWNLOAD_CHUNK_SIZE,\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01martifact\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud_artifact_repo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CloudArtifactRepository\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_databricks_workspace_client\u001b[39m():\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatabricks\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msdk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WorkspaceClient\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\MLflow Learning\\.venv\\Lib\\site-packages\\mlflow\\store\\artifact\\cloud_artifact_repo.py:20\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvironment_variables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     _MLFLOW_MPD_NUM_RETRIES,\n\u001b[32m     13\u001b[39m     _MLFLOW_MPD_RETRY_INTERVAL_SECONDS,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     MLFLOW_MULTIPART_UPLOAD_CHUNK_SIZE,\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MlflowException\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01martifact\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01martifact_repo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArtifactRepository\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chunk_list\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     23\u001b[39m     ArtifactProgressBar,\n\u001b[32m     24\u001b[39m     parallelized_download_file_using_http_uri,\n\u001b[32m     25\u001b[39m     relative_path_to_artifact_path,\n\u001b[32m     26\u001b[39m     remove_on_error,\n\u001b[32m     27\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\MLflow Learning\\.venv\\Lib\\site-packages\\mlflow\\store\\artifact\\artifact_repo.py:32\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mannotations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m developer_stable\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01masync_logging\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01masync_artifacts_logging_queue\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     30\u001b[39m     AsyncArtifactsLoggingQueue,\n\u001b[32m     31\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArtifactProgressBar, create_tmp_dir\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bad_path_message, path_not_unique\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Constants used to determine max level of parallelism to use while uploading/downloading artifacts.\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Max threads to use for parallelism.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\MLflow Learning\\.venv\\Lib\\site-packages\\mlflow\\utils\\file_utils.py:61\u001b[39m\n\u001b[32m     59\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CSafeDumper \u001b[38;5;28;01mas\u001b[39;00m YamlSafeDumper\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SafeDumper \u001b[38;5;28;01mas\u001b[39;00m YamlSafeDumper  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mArtifactProgressBar\u001b[39;00m:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, desc, total, step, **kwargs) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mImportError\u001b[39m: cannot import name 'SafeDumper' from 'yaml' (unknown location)"
          ]
        }
      ],
      "source": [
        "# Set up the environment\n",
        "import os\n",
        "import mlflow\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Direct Access to Model Provider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'mlflow' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Configure MLflow for tracking LLM models\u001b[39;00m\n\u001b[32m      2\u001b[39m tracking_uri = \u001b[33m\"\u001b[39m\u001b[33mfile:./mlruns\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mmlflow\u001b[49m.set_tracking_uri(tracking_uri)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMLflow tracking URI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmlflow.get_tracking_uri()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMLflow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmlflow.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'mlflow' is not defined"
          ]
        }
      ],
      "source": [
        "# Configure MLflow for tracking LLM models\n",
        "tracking_uri = \"file:./mlruns\"\n",
        "mlflow.set_tracking_uri(tracking_uri)\n",
        "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
        "print(f\"MLflow version: {mlflow.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Using existing experiment: genai-llm-tracking (ID: 259579753193701999)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='file:///e:/MLflow Learning/mlruns/259579753193701999', creation_time=1753480536189, experiment_id='259579753193701999', last_update_time=1753480536189, lifecycle_stage='active', name='genai-llm-tracking', tags={}>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create experiment\n",
        "experiment_name = \"genai-llm-tracking\"\n",
        "try:\n",
        "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "    if experiment is None:\n",
        "        experiment_id = mlflow.create_experiment(experiment_name)\n",
        "        print(f\"✅ Created new experiment: {experiment_name} (ID: {experiment_id})\")\n",
        "    else:\n",
        "        experiment_id = experiment.experiment_id\n",
        "        print(f\"✅ Using existing experiment: {experiment_name} (ID: {experiment_id})\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error creating experiment: {e}\")\n",
        "    \n",
        "    # Fallback: create with different approach\n",
        "    experiment_id = mlflow.create_experiment(experiment_name)\n",
        "\n",
        "# Set active experiment\n",
        "mlflow.set_experiment(experiment_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Machine Learning: An In-Depth Explanation**\n",
            "\n",
            "**Introduction**\n",
            "\n",
            "Machine learning (ML) is a branch of artificial intelligence (AI) that enables computers to learn from data and make decisions or predictions without being explicitly programmed for specific tasks. Over the past few decades, machine learning has revolutionized numerous industries, from healthcare and finance to entertainment and transportation. This essay provides a comprehensive overview of machine learning, including its definition, types, key concepts, algorithms, applications, challenges, and future prospects.\n",
            "\n",
            "---\n",
            "\n",
            "**What is Machine Learning?**\n",
            "\n",
            "At its core, machine learning is about developing algorithms that can identify patterns in data and use those patterns to make predictions or decisions. Unlike traditional programming, where a developer writes explicit instructions for the computer to follow, machine learning systems are trained using large datasets. The system “learns” by adjusting its internal parameters to minimize errors in its predictions.\n",
            "\n",
            "Arthur Samuel, a pioneer in the field, defined machine learning as the “field of study that gives computers the ability to learn without being explicitly programmed.” This learning process is typically iterative, involving the continuous improvement of the model as it is exposed to more data.\n",
            "\n",
            "---\n",
            "\n",
            "**Types of Machine Learning**\n",
            "\n",
            "Machine learning can be broadly categorized into three main types:\n",
            "\n",
            "1. **Supervised Learning**\n",
            "   - In supervised learning, the algorithm is trained on a labeled dataset, meaning each input comes with a corresponding correct output (label). The goal is for the model to learn the mapping from inputs to outputs so it can predict the label for new, unseen data.\n",
            "   - Examples: Email spam detection, image classification, and credit scoring.\n",
            "\n",
            "2. **Unsupervised Learning**\n",
            "   - Here, the algorithm is given data without explicit labels. The goal is to find hidden patterns or structures within the data.\n",
            "   - Examples: Customer segmentation, anomaly detection, and topic modeling.\n",
            "\n",
            "3. **Reinforcement Learning**\n",
            "   - In reinforcement learning, an agent interacts with an environment and learns to take actions that maximize some notion of cumulative reward. The agent receives feedback in the form of rewards or penalties and uses this to improve its strategy over time.\n",
            "   - Examples: Game playing (like AlphaGo), robotics, and autonomous vehicles.\n",
            "\n",
            "---\n",
            "\n",
            "**Key Concepts in Machine Learning**\n",
            "\n",
            "1. **Data**\n",
            "   - Data is the foundation of machine learning. The quality and quantity of data directly impact the performance of ML models. Data can be structured (like tables in a database) or unstructured (like text, images, or audio).\n",
            "\n",
            "2. **Features and Labels**\n",
            "   - Features are the input variables used to make predictions. Labels are the outputs or targets the model aims to predict (in supervised learning).\n",
            "\n",
            "3. **Model**\n",
            "   - A model is a mathematical representation of a real-world process. It takes input features and produces an output (prediction).\n",
            "\n",
            "4. **Training and Testing**\n",
            "   - The dataset is typically split into a training set (used to train the model) and a testing set (used to evaluate its performance).\n",
            "\n",
            "5. **Loss Function**\n",
            "   - The loss function measures how well the model’s predictions match the actual labels. The goal of training is to minimize this loss.\n",
            "\n",
            "6. **Overfitting and Underfitting**\n",
            "   - Overfitting occurs when a model learns the training data too well, including its noise, and performs poorly on new data. Underfitting happens when the model is too simple to capture the underlying patterns.\n",
            "\n",
            "---\n",
            "\n",
            "**Common Machine Learning Algorithms**\n",
            "\n",
            "1. **Linear Regression**\n",
            "   - Used for predicting a continuous value. It models the relationship between input features and the output as a straight line.\n",
            "\n",
            "2. **Logistic Regression**\n",
            "   - Used for binary classification problems. It predicts the probability that an input belongs to a particular class.\n",
            "\n",
            "3. **Decision Trees**\n",
            "   - These models split the data into branches based on feature values, making decisions at each node.\n",
            "\n",
            "4. **Random Forests**\n",
            "   - An ensemble of decision trees that improves prediction accuracy by averaging the results of multiple trees.\n",
            "\n",
            "5. **Support Vector Machines (SVM)**\n",
            "   - SVMs find the optimal boundary (hyperplane) that separates different classes in the data.\n",
            "\n",
            "6. **K-Nearest Neighbors (KNN)**\n",
            "   - This algorithm classifies new data points based on the majority class among its k-nearest neighbors in the training set.\n",
            "\n",
            "7. **Neural Networks**\n",
            "   - Inspired by the human brain, neural networks consist of interconnected layers of nodes (neurons) that can model complex, non-linear relationships.\n",
            "\n",
            "8. **Clustering Algorithms (e.g., K-Means)**\n",
            "   - Used in unsupervised learning to group similar data points together.\n",
            "\n",
            "---\n",
            "\n",
            "**Applications of Machine Learning**\n",
            "\n",
            "Machine learning is ubiquitous in modern technology. Some notable applications include:\n",
            "\n",
            "- **Healthcare:** Disease diagnosis, personalized medicine, and drug discovery.\n",
            "- **Finance:** Fraud detection, algorithmic trading, and credit risk assessment.\n",
            "- **Retail:** Recommendation systems, inventory management\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import mlflow\n",
        "\n",
        "with mlflow.start_run(run_name=\"openai-llm-tracking-2\"):\n",
        "    # Enable auto-tracing for OpenAI\n",
        "    mlflow.openai.autolog()\n",
        "\n",
        "    # Initialize the OpenAI client\n",
        "    openai_client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "    # Define the messages\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\", \n",
        "            \"content\": \"You are a helpful assistant.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the concept of machine learning in 1000 words.\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Make the request and print the response\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4.1\",\n",
        "        messages=messages,\n",
        "        temperature=0.1,\n",
        "        max_tokens=1000,\n",
        "    )\n",
        "\n",
        "    print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Total token usage: ==\n",
            "  Input tokens: 29\n",
            "  Output tokens: 1000\n",
            "  Total tokens: 1029\n",
            "\n",
            "== Detailed usage for each LLM call: ==\n",
            "Completions:\n",
            "  Input tokens: 29\n",
            "  Output tokens: 1000\n",
            "  Total tokens: 1029\n"
          ]
        }
      ],
      "source": [
        "# Get the trace object just created\n",
        "# Define a function to print the token usage\n",
        "def print_token_usage(trace):\n",
        "    # Print the token usage\n",
        "    total_usage = trace.info.token_usage\n",
        "    print(\"== Total token usage: ==\")\n",
        "    print(f\"  Input tokens: {total_usage['input_tokens']}\")\n",
        "    print(f\"  Output tokens: {total_usage['output_tokens']}\")\n",
        "    print(f\"  Total tokens: {total_usage['total_tokens']}\")\n",
        "\n",
        "    # Print the token usage for each LLM call\n",
        "    print(\"\\n== Detailed usage for each LLM call: ==\")\n",
        "    for span in trace.data.spans:\n",
        "        if usage := span.get_attribute(\"mlflow.chat.tokenUsage\"):\n",
        "            print(f\"{span.name}:\")\n",
        "            print(f\"  Input tokens: {usage['input_tokens']}\")\n",
        "            print(f\"  Output tokens: {usage['output_tokens']}\")\n",
        "            print(f\"  Total tokens: {usage['total_tokens']}\")\n",
        "\n",
        "# Get the trace object just created\n",
        "last_trace_id = mlflow.get_last_active_trace_id()\n",
        "trace = mlflow.get_trace(trace_id=last_trace_id)\n",
        "print_token_usage(trace)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Google Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Machine learning (ML) is a subset of artificial intelligence (AI) that empowers computer systems to \"learn\" from data, identify patterns, and make decisions or predictions with minimal human intervention.\n",
            "\n",
            "Think of it this way:\n",
            "\n",
            "*   **Traditional Programming:** You write explicit instructions for the computer to follow. If you want it to classify an email as spam, you'd write rules like \"If sender is X AND subject contains Y, then it's spam.\"\n",
            "*   **Machine Learning:** You *don't* write explicit rules for every scenario. Instead, you feed the machine a massive amount of data (e.g., millions of emails, some marked \"spam\" and some \"not spam\"). The machine then *learns* on its own to identify the characteristics that distinguish spam from legitimate emails. It builds its own internal \"model\" or \"rules\" based on the patterns it finds in the data.\n",
            "\n",
            "### The Core Concept: Learning from Data\n",
            "\n",
            "At its heart, machine learning is about **systems that improve their performance on a specific task with experience (data), without being explicitly programmed for every possible situation.**\n",
            "\n",
            "**Here's a breakdown of how it generally works:**\n",
            "\n",
            "1.  **Data Collection:** Gathering relevant data is the first step. This could be anything from images, text, numbers, sounds, or sensor readings. The quality and quantity of data are crucial.\n",
            "2.  **Feature Extraction (Optional but Common):** Identifying the important characteristics (features) within the data that are relevant to the problem. For an image of an animal, features might be ear shape, fur color, tail length, etc. (Though deep learning often automates this).\n",
            "3.  **Algorithm Selection:** Choosing a suitable machine learning algorithm. There are many types, each suited for different problems (e.g., decision trees, neural networks, support vector machines).\n",
            "4.  **Training the Model:** The chosen algorithm \"learns\" from the collected data. During this phase, the algorithm processes the data, identifies patterns, and adjusts its internal parameters to build a \"model.\" This model is essentially the learned knowledge.\n",
            "5.  **Evaluation:** After training, the model's performance is tested on new, unseen data to see how well it generalizes and makes accurate predictions.\n",
            "6.  **Prediction/Decision:** Once the model is trained and deemed accurate, it can be deployed to make predictions or decisions on new, real-world data it has never encountered before. As it encounters more data, it can often be retrained and refined to improve further.\n",
            "\n",
            "### Why Do We Use Machine Learning?\n",
            "\n",
            "*   **Automation of Complex Tasks:** For problems where traditional rule-based programming is too difficult or impossible (e.g., recognizing faces, understanding human speech).\n",
            "*   **Handling Large Datasets:** Machines can sift through petabytes of data to find hidden patterns that humans would never spot.\n",
            "*   **Adaptability:** Systems can evolve and improve over time as more data becomes available, making them resilient to changing conditions.\n",
            "*   **Personalization:** Tailoring experiences to individual users (e.g., product recommendations, personalized content feeds).\n",
            "*   **Discovering Insights:** Uncovering unknown relationships and trends in data that can lead to new discoveries or business opportunities.\n",
            "\n",
            "### Key Types of Machine Learning\n",
            "\n",
            "There are three main categories of machine learning:\n",
            "\n",
            "1.  **Supervised Learning:**\n",
            "    *   **Concept:** Learning from *labeled* data, where each input has a corresponding correct output. It's like learning with a teacher.\n",
            "    *   **Examples:**\n",
            "        *   **Classification:** Predicting a category (e.g., spam/not spam, dog/cat, fraud/not fraud).\n",
            "        *   **Regression:** Predicting a continuous value (e.g., house prices, stock market trends, temperature).\n",
            "    *   **How it works:** The model learns a mapping from inputs to outputs based on the examples it's given.\n",
            "\n",
            "2.  **Unsupervised Learning:**\n",
            "    *   **Concept:** Learning from *unlabeled* data, where there are no predefined outputs. The goal is to find hidden structures, patterns, or relationships within the data itself. It's like learning without a teacher, just exploring.\n",
            "    *   **Examples:**\n",
            "        *   **Clustering:** Grouping similar data points together (e.g., customer segmentation, identifying different types of news articles).\n",
            "        *   **Dimensionality Reduction:** Simplifying complex data by reducing the number of variables while retaining important information.\n",
            "    *   **How it works:** The algorithm looks for natural groupings or underlying structures in the data.\n",
            "\n",
            "3.  **Reinforcement Learning:**\n",
            "    *   **Concept:** Learning by trial and error, through interaction with an environment. An \"agent\" performs actions in an environment and receives rewards for desired behaviors and penalties for undesired ones. It's like training a pet.\n",
            "    *   **Examples:**\n",
            "        *   Teaching a robot to walk.\n",
            "        *   Playing complex games (e.g., AlphaGo beating the world champion at Go).\n",
            "        *   Autonomous driving.\n",
            "    *   **How it works:** The agent learns a \"policy\" – a strategy for choosing actions that maximize cumulative reward over time.\n",
            "\n",
            "### Real-World Applications of Machine Learning:\n",
            "\n",
            "*   **Email Spam Filtering:** Automatically identifying and isolating unwanted emails.\n",
            "*   **Recommendation Systems:** Suggesting movies, products, or music (Netflix, Amazon, Spotify).\n",
            "*   **Image and Speech Recognition:** Unlocking phones with your face, voice assistants (Siri, Alexa), transcribing audio.\n",
            "*   **Medical Diagnosis:** Assisting doctors in identifying diseases from medical images (X-rays, MRIs).\n",
            "*   **Fraud Detection:** Flagging suspicious transactions in banking and credit card systems.\n",
            "*   **Autonomous Vehicles:** Enabling cars to perceive their surroundings and navigate.\n",
            "*   **Natural Language Processing (NLP):** Translation services (Google Translate), sentiment analysis, chatbots.\n",
            "*   **Predictive Analytics:** Forecasting sales, stock prices, or weather patterns.\n",
            "\n",
            "In essence, machine learning is about empowering computers to learn and adapt from data, allowing them to perform tasks that were once considered exclusively within the realm of human intelligence.\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "import os\n",
        "import google.genai as genai\n",
        "from google.genai import types\n",
        "\n",
        "with mlflow.start_run(run_name=\"gemini-llm-tracking\"):\n",
        "    # Turn on auto tracing for Gemini\n",
        "    mlflow.gemini.autolog()\n",
        "\n",
        "    # Configure the SDK with your API key.\n",
        "    client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "    # Use the generate_content method to generate responses to your prompts.\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\", \n",
        "        contents=\"Explain the concept of machine learning\"\n",
        "        # config=types.GenerateContentConfig(\n",
        "        #     temperature=0.1,\n",
        "        #     max_output_tokens=500,\n",
        "        # )\n",
        "    )\n",
        "\n",
        "    print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n",
            "1303\n"
          ]
        }
      ],
      "source": [
        "print(response.usage_metadata.prompt_token_count)\n",
        "print(response.usage_metadata.candidates_token_count)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
