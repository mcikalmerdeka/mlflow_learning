{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# MLflow Tutorial: Hands-on Examples\n",
        "\n",
        "This notebook provides practical examples of MLflow usage for data science MLOps. Also include the testing for tracking LLM application.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Make sure you have installed the dependencies using UV:\n",
        "```bash\n",
        "uv add mlflow scikit-learn pandas numpy matplotlib seaborn dotenv ipykernel\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup and Basic Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLflow tracking URI: file:./mlruns\n",
            "MLflow version: 3.1.4\n"
          ]
        }
      ],
      "source": [
        "# Importing Libraries\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import mlflow.models\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# # Classical ML Libraries\n",
        "# from sklearn.datasets import load_iris, load_wine\n",
        "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# LLM Libraries\n",
        "import openai\n",
        "\n",
        "# Configure MLflow for tracking classical ML models\n",
        "tracking_uri = \"file:./mlruns\"\n",
        "mlflow.set_tracking_uri(tracking_uri)\n",
        "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
        "print(f\"MLflow version: {mlflow.__version__}\")\n",
        "\n",
        "# Configure MLflow for tracking LLM models\n",
        "tracking_uri = \"file:./llm_runs\"\n",
        "mlflow.set_tracking_uri(tracking_uri)\n",
        "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
        "print(f\"MLflow version: {mlflow.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: We can change the location of backend store in local or other server. Please refer to this link: [MLflow Backend Stores](https://mlflow.org/docs/latest/ml/tracking/backend-stores/#:~:text=By%20default%2C%20MLflow%20stores%20metadata,Set%20the%20MLFLOW_TRACKING_URI%20environment%20variable.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classical ML Tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 1. Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iris dataset: (150, 4), classes: 3\n",
            "Wine dataset: (178, 13), classes: 3\n"
          ]
        }
      ],
      "source": [
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X_iris, y_iris = iris.data, iris.target\n",
        "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
        "    X_iris, y_iris, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Load Wine dataset for additional examples\n",
        "wine = load_wine()\n",
        "X_wine, y_wine = wine.data, wine.target\n",
        "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(\n",
        "    X_wine, y_wine, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Iris dataset: {X_iris.shape}, classes: {len(np.unique(y_iris))}\")\n",
        "print(f\"Wine dataset: {X_wine.shape}, classes: {len(np.unique(y_wine))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 2. Basic MLflow Tracking\n",
        "\n",
        "This section includes:\n",
        "\n",
        "- Creating an experiment\n",
        "\n",
        "- Creating a run\n",
        "    - Single run\n",
        "    - Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Using existing experiment: iris-classification-tutorial (ID: 623039503078250544)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='file:///e:/mlflow_testing/mlruns/623039503078250544', creation_time=1753396716576, experiment_id='623039503078250544', last_update_time=1753396716576, lifecycle_stage='active', name='iris-classification-tutorial', tags={}>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create experiment\n",
        "experiment_name = \"iris-classification-tutorial\"\n",
        "try:\n",
        "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "    if experiment is None:\n",
        "        experiment_id = mlflow.create_experiment(experiment_name)\n",
        "        print(f\"‚úÖ Created new experiment: {experiment_name} (ID: {experiment_id})\")\n",
        "    else:\n",
        "        experiment_id = experiment.experiment_id\n",
        "        print(f\"‚úÖ Using existing experiment: {experiment_name} (ID: {experiment_id})\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error creating experiment: {e}\")\n",
        "    \n",
        "    # Fallback: create with different approach\n",
        "    experiment_id = mlflow.create_experiment(experiment_name)\n",
        "\n",
        "# Set active experiment\n",
        "mlflow.set_experiment(experiment_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check all past runs in the experiment\n",
        "runs = mlflow.search_runs(experiment_ids=[experiment_id])\n",
        "print(f\"Found {len(runs)} runs in experiment '{experiment_name}'\")\n",
        "display(runs[['run_id', 'start_time', 'end_time', 'status']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic tracking example - Single model run\n",
        "with mlflow.start_run(run_name=\"baseline-random-forest\"):\n",
        "    \n",
        "    # Single parameter values (not lists!)\n",
        "    n_estimators = 100\n",
        "    max_depth = 10\n",
        "    min_samples_split = 2\n",
        "    \n",
        "    # Log parameters\n",
        "    mlflow.log_param(\"model_type\", \"RandomForest\")\n",
        "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "    mlflow.log_param(\"max_depth\", max_depth)\n",
        "    mlflow.log_param(\"min_samples_split\", min_samples_split)\n",
        "    mlflow.log_param(\"dataset\", \"iris\")\n",
        "    mlflow.log_param(\"dataset_size\", len(X_train_iris))\n",
        "    \n",
        "    # Train model\n",
        "    start_time = time.perf_counter()\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train_iris, y_train_iris)\n",
        "    training_time = time.perf_counter() - start_time\n",
        "    \n",
        "    # Make predictions\n",
        "    y_pred_train = model.predict(X_train_iris)\n",
        "    y_pred_test = model.predict(X_test_iris)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    train_accuracy = accuracy_score(y_train_iris, y_pred_train)\n",
        "    test_accuracy = accuracy_score(y_test_iris, y_pred_test)\n",
        "    precision = precision_score(y_test_iris, y_pred_test, average='weighted')\n",
        "    recall = recall_score(y_test_iris, y_pred_test, average='weighted')\n",
        "    f1 = f1_score(y_test_iris, y_pred_test, average='weighted')\n",
        "    \n",
        "    # Log metrics\n",
        "    mlflow.log_metrics({\n",
        "        \"train_accuracy\": train_accuracy,\n",
        "        \"test_accuracy\": test_accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"training_time\": training_time\n",
        "    })\n",
        "    \n",
        "    # Log model with input example and signature (fixes warnings)\n",
        "    input_example = X_train_iris[:5]\n",
        "    mlflow.sklearn.log_model(\n",
        "        model, \n",
        "        \"model\",\n",
        "        input_example=input_example,\n",
        "        signature=mlflow.models.infer_signature(X_train_iris, y_pred_train)\n",
        "    )\n",
        "    \n",
        "    # Save and log confusion matrix\n",
        "    cm = confusion_matrix(y_test_iris, y_pred_test)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix - Random Forest')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig('confusion_matrix_rf.png', dpi=150, bbox_inches='tight')\n",
        "    mlflow.log_artifact('confusion_matrix_rf.png')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"Training time: {training_time:.2f} seconds\")\n",
        "    print(f\"Run ID: {mlflow.active_run().info.run_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Option 1: Manual Nested Runs (Educational)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HYPERPARAMETER TUNING WITH NESTED RUNS - BEST PRACTICE\n",
        "import itertools\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [5, 10],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = None\n",
        "best_model = None\n",
        "\n",
        "# Parent run for the entire tuning experiment\n",
        "with mlflow.start_run(run_name=\"hyperparameter-tuning-experiment\") as parent_run:\n",
        "    \n",
        "    # Log experiment metadata\n",
        "    mlflow.log_param(\"tuning_strategy\", \"grid_search\")\n",
        "    mlflow.log_param(\"param_space\", str(param_grid))\n",
        "    mlflow.log_param(\"total_combinations\", len(list(itertools.product(*param_grid.values()))))\n",
        "    \n",
        "    run_count = 0\n",
        "    \n",
        "    # Grid search with nested runs\n",
        "    for n_est in param_grid['n_estimators']:\n",
        "        for depth in param_grid['max_depth']:\n",
        "            for min_split in param_grid['min_samples_split']:\n",
        "                \n",
        "                run_count += 1\n",
        "                \n",
        "                # Child run for each parameter combination\n",
        "                with mlflow.start_run(run_name=f\"run_{run_count:02d}\", nested=True) as child_run:\n",
        "                    \n",
        "                    # Current parameter combination\n",
        "                    current_params = {\n",
        "                        \"n_estimators\": n_est,\n",
        "                        \"max_depth\": depth,\n",
        "                        \"min_samples_split\": min_split\n",
        "                    }\n",
        "                    \n",
        "                    # Log parameters\n",
        "                    mlflow.log_params({\n",
        "                        **current_params,\n",
        "                        \"model_type\": \"RandomForest\",\n",
        "                        \"dataset\": \"iris\",\n",
        "                        \"random_state\": 42\n",
        "                    })\n",
        "                    \n",
        "                    # Train model\n",
        "                    start_time = time.perf_counter()\n",
        "                    model = RandomForestClassifier(\n",
        "                        n_estimators=n_est,\n",
        "                        max_depth=depth,\n",
        "                        min_samples_split=min_split,\n",
        "                        random_state=42\n",
        "                    )\n",
        "                    model.fit(X_train_iris, y_train_iris)\n",
        "                    training_time = time.perf_counter() - start_time\n",
        "                    \n",
        "                    # Make predictions\n",
        "                    y_pred_train = model.predict(X_train_iris)\n",
        "                    y_pred_test = model.predict(X_test_iris)\n",
        "                    \n",
        "                    # Calculate metrics\n",
        "                    train_accuracy = accuracy_score(y_train_iris, y_pred_train)\n",
        "                    test_accuracy = accuracy_score(y_test_iris, y_pred_test)\n",
        "                    precision = precision_score(y_test_iris, y_pred_test, average='weighted')\n",
        "                    recall = recall_score(y_test_iris, y_pred_test, average='weighted')\n",
        "                    f1 = f1_score(y_test_iris, y_pred_test, average='weighted')\n",
        "                    \n",
        "                    # Log metrics\n",
        "                    mlflow.log_metrics({\n",
        "                        \"train_accuracy\": train_accuracy,\n",
        "                        \"test_accuracy\": test_accuracy,\n",
        "                        \"precision\": precision,\n",
        "                        \"recall\": recall,\n",
        "                        \"f1_score\": f1,\n",
        "                        \"training_time\": training_time\n",
        "                    })\n",
        "                    \n",
        "                    # Log model with signature (always include for best practices)\n",
        "                    input_example = X_train_iris[:3]\n",
        "                    mlflow.sklearn.log_model(\n",
        "                        model, \n",
        "                        \"model\",\n",
        "                        input_example=input_example,\n",
        "                        signature=mlflow.models.infer_signature(X_train_iris, y_pred_test)\n",
        "                    )\n",
        "                    \n",
        "                    # Track best model\n",
        "                    if test_accuracy > best_accuracy:\n",
        "                        best_accuracy = test_accuracy\n",
        "                        best_params = current_params.copy()\n",
        "                        best_model = model\n",
        "                    \n",
        "                    print(f\"Run {run_count:2d} | n_est={n_est:3d}, depth={depth:2d}, min_split={min_split:2d} | Accuracy: {test_accuracy:.4f}\")\n",
        "    \n",
        "    # Log best results to parent run\n",
        "    mlflow.log_params({f\"best_{k}\": v for k, v in best_params.items()})\n",
        "    mlflow.log_metric(\"best_test_accuracy\", best_accuracy)\n",
        "    mlflow.log_metric(\"total_runs\", run_count)\n",
        "    \n",
        "    # Register best model\n",
        "    if best_model is not None:\n",
        "        input_example = X_train_iris[:5]\n",
        "        mlflow.sklearn.log_model(\n",
        "            best_model,\n",
        "            \"best_model\", \n",
        "            input_example=input_example,\n",
        "            signature=mlflow.models.infer_signature(X_train_iris, best_model.predict(X_test_iris)),\n",
        "            registered_model_name=\"iris_best_rf_tuned\"\n",
        "        )\n",
        "    \n",
        "    print(f\"\\nüéØ TUNING COMPLETE!\")\n",
        "    print(f\"üìä Tested {run_count} parameter combinations\")\n",
        "    print(f\"üèÜ Best accuracy: {best_accuracy:.4f}\")\n",
        "    print(f\"‚öôÔ∏è  Best parameters: {best_params}\")\n",
        "    print(f\"üîÑ Parent run ID: {parent_run.info.run_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "#### Option 2: Using GridSearchCV with MLflow Autologging (Recommended for Hyperparameter Tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/07/25 16:32:10 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 1.3.0 <= scikit-learn <= 1.7.0, but the installed version is 1.7.1. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Running GridSearchCV with 3-fold CV...\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/07/25 16:32:32 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
            "2025/07/25 16:32:35 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
            "2025/07/25 16:32:35 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÜ GRIDSEARCH COMPLETE!\n",
            "üìä Best CV score: 0.9583\n",
            "üéØ Holdout test accuracy: 1.0000\n",
            "‚öôÔ∏è  Best parameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "ü§ñ All runs auto-logged to MLflow!\n"
          ]
        }
      ],
      "source": [
        "# OPTION 2: GridSearchCV with MLflow Autologging - EVEN EASIER!\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Enable autologging for sklearn (captures GridSearchCV automatically)\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid_cv = {\n",
        "    'n_estimators': [50, 75],\n",
        "    'max_depth': [5, 10],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# Create experiment for GridSearchCV\n",
        "mlflow.set_experiment(\"iris-gridsearch-autolog\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"gridsearch-with-autolog-2\") as run:\n",
        "    \n",
        "    # Create base model\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "    \n",
        "    # Create GridSearchCV\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=rf,\n",
        "        param_grid=param_grid_cv,\n",
        "        cv=3,  # 3-fold cross-validation\n",
        "        scoring='accuracy', # set scoring to accuracy\n",
        "        n_jobs=-1,  # Use all cores\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    print(\"üîç Running GridSearchCV with 3-fold CV...\")\n",
        "    \n",
        "    # Fit - this will automatically log everything to MLflow!\n",
        "    grid_search.fit(X_train_iris, y_train_iris)\n",
        "    \n",
        "    # Get best results\n",
        "    best_model = grid_search.best_estimator_\n",
        "    best_params = grid_search.best_params_\n",
        "    best_score = grid_search.best_score_\n",
        "    \n",
        "    # Test on holdout set\n",
        "    test_accuracy = best_model.score(X_test_iris, y_test_iris)\n",
        "    \n",
        "    # Log additional custom metrics\n",
        "    mlflow.log_metric(\"holdout_test_accuracy\", test_accuracy)\n",
        "    mlflow.log_param(\"cv_folds\", 5)\n",
        "    mlflow.log_param(\"total_combinations_tested\", len(grid_search.cv_results_['mean_test_score']))\n",
        "    \n",
        "    print(f\"\\nüèÜ GRIDSEARCH COMPLETE!\")\n",
        "    print(f\"üìä Best CV score: {best_score:.4f}\")\n",
        "    print(f\"üéØ Holdout test accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"‚öôÔ∏è  Best parameters: {best_params}\")\n",
        "    print(f\"ü§ñ All runs auto-logged to MLflow!\")\n",
        "\n",
        "# Disable autologging\n",
        "mlflow.sklearn.autolog(disable=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "#### Option 3: RandomizedSearchCV for Large Parameter Spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPTION 3: RandomizedSearchCV for large parameter spaces\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Enable autologging again\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "# Define LARGE parameter space with distributions\n",
        "param_distributions = {\n",
        "    'n_estimators': randint(50, 300),  # Random integers between 50-300\n",
        "    'max_depth': randint(3, 20),       # Random integers between 3-20\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'max_features': uniform(0.1, 0.8)  # Random float between 0.1-0.9\n",
        "}\n",
        "\n",
        "# Set experiment\n",
        "mlflow.set_experiment(\"iris-randomized-search\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"randomized-search-efficient\") as run:\n",
        "    \n",
        "    # Create base model\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "    \n",
        "    # Create RandomizedSearchCV - only test 20 random combinations\n",
        "    random_search = RandomizedSearchCV(\n",
        "        estimator=rf,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=20,  # Only test 20 random combinations (vs 100+ in full grid)\n",
        "        cv=3,       # 3-fold CV for speed\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    print(\"üé≤ Running RandomizedSearchCV (20 random combinations)...\")\n",
        "    \n",
        "    # Fit - auto-logged to MLflow\n",
        "    random_search.fit(X_train_iris, y_train_iris)\n",
        "    \n",
        "    # Get results\n",
        "    best_model = random_search.best_estimator_\n",
        "    best_params = random_search.best_params_\n",
        "    best_score = random_search.best_score_\n",
        "    test_accuracy = best_model.score(X_test_iris, y_test_iris)\n",
        "    \n",
        "    # Log additional metrics\n",
        "    mlflow.log_metric(\"holdout_test_accuracy\", test_accuracy)\n",
        "    mlflow.log_param(\"search_type\", \"randomized\")\n",
        "    mlflow.log_param(\"n_iter\", 20)\n",
        "    \n",
        "    print(f\"\\nüéØ RANDOMIZED SEARCH COMPLETE!\")\n",
        "    print(f\"üìä Best CV score: {best_score:.4f}\")\n",
        "    print(f\"üéØ Holdout test accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"‚öôÔ∏è  Best parameters: {best_params}\")\n",
        "    print(f\"‚ö° Much faster than full grid search!\")\n",
        "\n",
        "# Disable autologging\n",
        "mlflow.sklearn.autolog(disable=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "#### üéØ Hyperparameter Tuning Summary: Choose Your Approach\n",
        "\n",
        "| **Method** | **When to Use** | **Pros** | **Cons** |\n",
        "|------------|-----------------|----------|----------|\n",
        "| **Manual Nested Runs** | Learning MLflow, custom logic needed | Full control, educational | More code, manual loops |\n",
        "| **GridSearchCV + Autolog** | Small parameter spaces, want all combinations | Easy, automatic logging | Can be slow for large grids |\n",
        "| **RandomizedSearchCV + Autolog** | Large parameter spaces, time constraints | Fast, good coverage, automatic | May miss optimal combination |\n",
        "\n",
        "#### üèÜ **Best Practices Recommendations:**\n",
        "\n",
        "1. **Start Simple**: Use GridSearchCV with autologging for most cases\n",
        "2. **Go Manual**: Use nested runs when you need custom experiment logic\n",
        "3. **Scale Up**: Use RandomizedSearchCV for large parameter spaces (>100 combinations)\n",
        "4. **Always Log**: Include `input_example` and `signature` in model logging\n",
        "5. **Track Best**: Use parent runs to summarize tuning experiments\n",
        "6. **Name Wisely**: Use descriptive run names and experiment names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 3. Compare Multiple Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare different models\n",
        "models_config = [\n",
        "    {\n",
        "        \"name\": \"logistic-regression\",\n",
        "        \"model\": LogisticRegression(random_state=42, max_iter=1000),\n",
        "        \"params\": {\"solver\": \"lbfgs\", \"max_iter\": 1000}\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"random-forest-small\",\n",
        "        \"model\": RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42),\n",
        "        \"params\": {\"n_estimators\": 50, \"max_depth\": 5}\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"random-forest-large\", \n",
        "        \"model\": RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42),\n",
        "        \"params\": {\"n_estimators\": 200, \"max_depth\": 15}\n",
        "    }\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "with mlflow.start_run(run_name=\"model-comparison\"):\n",
        "    for config in models_config:\n",
        "        with mlflow.start_run(run_name=config[\"name\"], nested=True):\n",
        "            # Log parameters\n",
        "            mlflow.log_param(\"model_type\", config[\"name\"])\n",
        "            mlflow.log_params(config[\"params\"])\n",
        "            \n",
        "            # Train model\n",
        "            start_time = time.time()\n",
        "            model = config[\"model\"]\n",
        "            model.fit(X_train_iris, y_train_iris)\n",
        "            training_time = time.time() - start_time\n",
        "            \n",
        "            # Evaluate\n",
        "            test_accuracy = accuracy_score(y_test_iris, model.predict(X_test_iris))\n",
        "            \n",
        "            # Log metrics\n",
        "            mlflow.log_metrics({\n",
        "                \"test_accuracy\": test_accuracy,\n",
        "                \"training_time\": training_time\n",
        "            })\n",
        "            \n",
        "            # Log model with input example and signature\n",
        "            input_example = X_train_iris[:3]\n",
        "            mlflow.sklearn.log_model(\n",
        "                model, \n",
        "                \"model\",\n",
        "                input_example=input_example,\n",
        "                signature=mlflow.models.infer_signature(X_train_iris, model.predict(X_test_iris))\n",
        "            )\n",
        "            \n",
        "            results.append({\n",
        "                \"model\": config[\"name\"],\n",
        "                \"accuracy\": test_accuracy,\n",
        "                \"training_time\": training_time\n",
        "            })\n",
        "            \n",
        "            print(f\"{config['name']}: {test_accuracy:.4f} accuracy, {training_time:.2f}s\")\n",
        "\n",
        "# Display results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nModel Comparison Results:\")\n",
        "print(results_df.sort_values('accuracy', ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 4. Hyperparameter Tuning with MLflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter tuning with nested runs\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [5, 10, 15, None]\n",
        "}\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = None\n",
        "\n",
        "with mlflow.start_run(run_name=\"hyperparameter-tuning\"):\n",
        "    mlflow.log_param(\"tuning_strategy\", \"grid_search\")\n",
        "    mlflow.log_param(\"param_space\", str(param_grid))\n",
        "    \n",
        "    for n_est in param_grid['n_estimators']:\n",
        "        for depth in param_grid['max_depth']:\n",
        "            with mlflow.start_run(nested=True):\n",
        "                # Log parameters\n",
        "                params = {\n",
        "                    \"n_estimators\": n_est,\n",
        "                    \"max_depth\": depth if depth is not None else \"None\"\n",
        "                }\n",
        "                mlflow.log_params(params)\n",
        "                \n",
        "                # Train model\n",
        "                model = RandomForestClassifier(\n",
        "                    n_estimators=n_est, \n",
        "                    max_depth=depth, \n",
        "                    random_state=42\n",
        "                )\n",
        "                model.fit(X_train_iris, y_train_iris)\n",
        "                \n",
        "                # Evaluate\n",
        "                accuracy = accuracy_score(y_test_iris, model.predict(X_test_iris))\n",
        "                mlflow.log_metric(\"test_accuracy\", accuracy)\n",
        "                \n",
        "                # Track best model\n",
        "                if accuracy > best_accuracy:\n",
        "                    best_accuracy = accuracy\n",
        "                    best_params = params.copy()\n",
        "                    # Log best model with signature\n",
        "                    input_example = X_train_iris[:3]\n",
        "                    mlflow.sklearn.log_model(\n",
        "                        model, \n",
        "                        \"model\",\n",
        "                        input_example=input_example,\n",
        "                        signature=mlflow.models.infer_signature(X_train_iris, model.predict(X_test_iris))\n",
        "                    )\n",
        "                \n",
        "                print(f\"n_est={n_est}, depth={depth}: {accuracy:.4f}\")\n",
        "    \n",
        "    # Log best results to parent run\n",
        "    mlflow.log_params({f\"best_{k}\": v for k, v in best_params.items()})\n",
        "    mlflow.log_metric(\"best_accuracy\", best_accuracy)\n",
        "\n",
        "print(f\"\\nBest accuracy: {best_accuracy:.4f}\")\n",
        "print(f\"Best parameters: {best_params}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 5. Model Registration and Versioning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train final model and register it\n",
        "with mlflow.start_run(run_name=\"production-model\"):\n",
        "    # Use best parameters from tuning\n",
        "    final_model = RandomForestClassifier(\n",
        "        n_estimators=100, \n",
        "        max_depth=10, \n",
        "        random_state=42\n",
        "    )\n",
        "    final_model.fit(X_train_iris, y_train_iris)\n",
        "    \n",
        "    # Evaluate\n",
        "    test_accuracy = accuracy_score(y_test_iris, final_model.predict(X_test_iris))\n",
        "    \n",
        "    # Log everything\n",
        "    mlflow.log_params({\n",
        "        \"n_estimators\": 100,\n",
        "        \"max_depth\": 10,\n",
        "        \"model_purpose\": \"production\"\n",
        "    })\n",
        "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
        "    \n",
        "    # Register model with signature and input example\n",
        "    input_example = X_train_iris[:5]\n",
        "    model_info = mlflow.sklearn.log_model(\n",
        "        final_model, \n",
        "        \"model\",\n",
        "        input_example=input_example,\n",
        "        signature=mlflow.models.infer_signature(X_train_iris, final_model.predict(X_test_iris)),\n",
        "        registered_model_name=\"iris_classifier\"\n",
        "    )\n",
        "    \n",
        "    print(f\"Model registered with accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"Model URI: {model_info.model_uri}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 6. Model Registry Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "client = MlflowClient()\n",
        "\n",
        "# List registered models\n",
        "registered_models = client.search_registered_models()\n",
        "print(\"Registered models:\")\n",
        "for model in registered_models:\n",
        "    print(f\"- {model.name}\")\n",
        "    for version in model.latest_versions:\n",
        "        print(f\"  Version {version.version}: {version.current_stage}\")\n",
        "\n",
        "# Get model details\n",
        "if registered_models:\n",
        "    model_name = \"iris_classifier\"\n",
        "    model_version = client.get_latest_versions(model_name)[0]\n",
        "    print(f\"\\nLatest version of {model_name}: {model_version.version}\")\n",
        "    \n",
        "    # Transition to staging\n",
        "    client.transition_model_version_stage(\n",
        "        name=model_name,\n",
        "        version=model_version.version,\n",
        "        stage=\"Staging\"\n",
        "    )\n",
        "    print(f\"Model {model_name} v{model_version.version} moved to Staging\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 7. Loading and Using Registered Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model from registry\n",
        "try:\n",
        "    # Load latest staging model\n",
        "    staging_model = mlflow.pyfunc.load_model(\"models:/iris_classifier/Staging\")\n",
        "    print(\"Loaded model from Staging\")\n",
        "    \n",
        "    # Make predictions\n",
        "    sample_data = X_test_iris[:5]\n",
        "    predictions = staging_model.predict(sample_data)\n",
        "    \n",
        "    print(\"\\nSample predictions:\")\n",
        "    for i, (sample, pred, actual) in enumerate(zip(sample_data, predictions, y_test_iris[:5])):\n",
        "        print(f\"Sample {i+1}: Predicted={pred}, Actual={actual}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    print(\"This might happen if no model is in Staging yet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 8. Advanced Features: Autologging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enable autologging\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "# Create new experiment for autologging\n",
        "mlflow.set_experiment(\"autologging-demo\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"autolog-example\"):\n",
        "    # Train model - everything is automatically logged!\n",
        "    auto_model = RandomForestClassifier(n_estimators=150, max_depth=12, random_state=42)\n",
        "    auto_model.fit(X_train_wine, y_train_wine)\n",
        "    \n",
        "    # Predictions are also logged\n",
        "    y_pred = auto_model.predict(X_test_wine)\n",
        "    accuracy = accuracy_score(y_test_wine, y_pred)\n",
        "    \n",
        "    print(f\"Autologged model accuracy on wine dataset: {accuracy:.4f}\")\n",
        "    print(\"Check MLflow UI to see all automatically logged parameters and metrics!\")\n",
        "\n",
        "# Disable autologging\n",
        "mlflow.sklearn.autolog(disable=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 9. Custom Artifacts and Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create experiment for custom artifacts\n",
        "mlflow.set_experiment(\"custom-artifacts-demo\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"custom-artifacts\"):\n",
        "    # Train model with preprocessing\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_wine)\n",
        "    X_test_scaled = scaler.transform(X_test_wine)\n",
        "    \n",
        "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "    model.fit(X_train_scaled, y_train_wine)\n",
        "    \n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test_wine, y_pred)\n",
        "    \n",
        "    # Log basic metrics\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_param(\"preprocessing\", \"StandardScaler\")\n",
        "    \n",
        "    # Save and log preprocessing artifacts\n",
        "    joblib.dump(scaler, \"scaler.pkl\")\n",
        "    mlflow.log_artifact(\"scaler.pkl\", \"preprocessing\")\n",
        "    \n",
        "    # Create feature importance plot\n",
        "    feature_names = wine.feature_names\n",
        "    if hasattr(model, 'coef_'):\n",
        "        importance = np.abs(model.coef_[0])\n",
        "        indices = np.argsort(importance)[::-1][:10]\n",
        "        \n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.title('Top 10 Feature Importance (Logistic Regression)')\n",
        "        plt.bar(range(10), importance[indices])\n",
        "        plt.xticks(range(10), [feature_names[i] for i in indices], rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')\n",
        "        mlflow.log_artifact('feature_importance.png', \"plots\")\n",
        "        plt.show()\n",
        "    \n",
        "    # Create classification report\n",
        "    from sklearn.metrics import classification_report\n",
        "    report = classification_report(y_test_wine, y_pred, target_names=wine.target_names)\n",
        "    \n",
        "    with open(\"classification_report.txt\", \"w\") as f:\n",
        "        f.write(report)\n",
        "    mlflow.log_artifact(\"classification_report.txt\", \"reports\")\n",
        "    \n",
        "    # Log model with signature and input example\n",
        "    input_example = X_train_scaled[:5]\n",
        "    mlflow.sklearn.log_model(\n",
        "        model, \n",
        "        \"model\",\n",
        "        input_example=input_example,\n",
        "        signature=mlflow.models.infer_signature(X_train_scaled, y_pred)\n",
        "    )\n",
        "    \n",
        "    print(f\"Wine classification accuracy: {accuracy:.4f}\")\n",
        "    print(\"Custom artifacts logged: scaler, feature importance plot, classification report\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 10. Experiment Analysis and Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Search and compare experiments\n",
        "from mlflow.entities import ViewType\n",
        "\n",
        "# Get all experiments\n",
        "experiments = client.search_experiments()\n",
        "print(\"Available experiments:\")\n",
        "for exp in experiments:\n",
        "    print(f\"- {exp.name} (ID: {exp.experiment_id})\")\n",
        "\n",
        "# Search runs from specific experiment\n",
        "iris_exp = mlflow.get_experiment_by_name(\"iris-classification-tutorial\")\n",
        "if iris_exp:\n",
        "    runs = client.search_runs(\n",
        "        experiment_ids=[iris_exp.experiment_id],\n",
        "        run_view_type=ViewType.ACTIVE_ONLY,\n",
        "        max_results=10\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nRuns in {iris_exp.name}:\")\n",
        "    for run in runs:\n",
        "        metrics = run.data.metrics\n",
        "        params = run.data.params\n",
        "        print(f\"Run: {run.info.run_name}\")\n",
        "        print(f\"  Accuracy: {metrics.get('test_accuracy', 'N/A')}\")\n",
        "        print(f\"  Model: {params.get('model_type', 'N/A')}\")\n",
        "        print(f\"  Status: {run.info.status}\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 11. Cleanup and Best Practices Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up temporary files\n",
        "import os\n",
        "temp_files = [\n",
        "    'confusion_matrix_rf.png', \n",
        "    'scaler.pkl', \n",
        "    'feature_importance.png',\n",
        "    'classification_report.txt'\n",
        "]\n",
        "\n",
        "for file in temp_files:\n",
        "    if os.path.exists(file):\n",
        "        os.remove(file)\n",
        "        print(f\"Removed {file}\")\n",
        "\n",
        "print(\"\\n=== MLflow Tutorial Complete ===\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Start MLflow UI: uv run mlflow ui\")\n",
        "print(\"2. Open http://localhost:5000 in your browser\")\n",
        "print(\"3. Explore your experiments, runs, and models!\")\n",
        "print(\"4. Try model serving: mlflow models serve -m 'models:/iris_classifier/Staging' -p 5001\")\n",
        "\n",
        "print(\"\\nKey takeaways:\")\n",
        "print(\"- Use experiments to organize related runs\")\n",
        "print(\"- Log parameters, metrics, and artifacts consistently\")\n",
        "print(\"- Use nested runs for hyperparameter tuning\")\n",
        "print(\"- Register important models for production use\")\n",
        "print(\"- Leverage autologging for quick experimentation\")\n",
        "print(\"- Save preprocessing artifacts for reproducibility\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LLM Application Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set up the environment\n",
        "import os\n",
        "import mlflow\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Direct Access to Model Provider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLflow tracking URI: file:./mlruns\n",
            "MLflow version: 3.1.4\n"
          ]
        }
      ],
      "source": [
        "# Configure MLflow for tracking LLM models\n",
        "tracking_uri = \"file:./mlruns\"\n",
        "mlflow.set_tracking_uri(tracking_uri)\n",
        "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
        "print(f\"MLflow version: {mlflow.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Using existing experiment: genai-llm-tracking (ID: 259579753193701999)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='file:///e:/MLflow Learning/mlruns/259579753193701999', creation_time=1753480536189, experiment_id='259579753193701999', last_update_time=1753480536189, lifecycle_stage='active', name='genai-llm-tracking', tags={}>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create experiment\n",
        "experiment_name = \"genai-llm-tracking\"\n",
        "try:\n",
        "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "    if experiment is None:\n",
        "        experiment_id = mlflow.create_experiment(experiment_name)\n",
        "        print(f\"‚úÖ Created new experiment: {experiment_name} (ID: {experiment_id})\")\n",
        "    else:\n",
        "        experiment_id = experiment.experiment_id\n",
        "        print(f\"‚úÖ Using existing experiment: {experiment_name} (ID: {experiment_id})\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error creating experiment: {e}\")\n",
        "    \n",
        "    # Fallback: create with different approach\n",
        "    experiment_id = mlflow.create_experiment(experiment_name)\n",
        "\n",
        "# Set active experiment\n",
        "mlflow.set_experiment(experiment_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Machine Learning: An In-Depth Explanation**\n",
            "\n",
            "**Introduction**\n",
            "\n",
            "Machine learning (ML) is a branch of artificial intelligence (AI) that enables computers to learn from data and make decisions or predictions without being explicitly programmed for specific tasks. Over the past few decades, machine learning has revolutionized numerous industries, from healthcare and finance to entertainment and transportation. This essay provides a comprehensive overview of machine learning, including its definition, types, key concepts, algorithms, applications, challenges, and future prospects.\n",
            "\n",
            "---\n",
            "\n",
            "**What is Machine Learning?**\n",
            "\n",
            "At its core, machine learning is about developing algorithms that can identify patterns in data and use those patterns to make predictions or decisions. Unlike traditional programming, where a developer writes explicit instructions for the computer to follow, machine learning systems are trained using large datasets. The system ‚Äúlearns‚Äù by adjusting its internal parameters to minimize errors in its predictions.\n",
            "\n",
            "Arthur Samuel, a pioneer in the field, defined machine learning as the ‚Äúfield of study that gives computers the ability to learn without being explicitly programmed.‚Äù This learning process is typically iterative, involving the continuous improvement of the model as it is exposed to more data.\n",
            "\n",
            "---\n",
            "\n",
            "**Types of Machine Learning**\n",
            "\n",
            "Machine learning can be broadly categorized into three main types:\n",
            "\n",
            "1. **Supervised Learning**\n",
            "   - In supervised learning, the algorithm is trained on a labeled dataset, meaning each input comes with a corresponding correct output (label). The goal is for the model to learn the mapping from inputs to outputs so it can predict the label for new, unseen data.\n",
            "   - Examples: Email spam detection, image classification, and credit scoring.\n",
            "\n",
            "2. **Unsupervised Learning**\n",
            "   - Here, the algorithm is given data without explicit labels. The goal is to find hidden patterns or structures within the data.\n",
            "   - Examples: Customer segmentation, anomaly detection, and topic modeling.\n",
            "\n",
            "3. **Reinforcement Learning**\n",
            "   - In reinforcement learning, an agent interacts with an environment and learns to take actions that maximize some notion of cumulative reward. The agent receives feedback in the form of rewards or penalties and uses this to improve its strategy over time.\n",
            "   - Examples: Game playing (like AlphaGo), robotics, and autonomous vehicles.\n",
            "\n",
            "---\n",
            "\n",
            "**Key Concepts in Machine Learning**\n",
            "\n",
            "1. **Data**\n",
            "   - Data is the foundation of machine learning. The quality and quantity of data directly impact the performance of ML models. Data can be structured (like tables in a database) or unstructured (like text, images, or audio).\n",
            "\n",
            "2. **Features and Labels**\n",
            "   - Features are the input variables used to make predictions. Labels are the outputs or targets the model aims to predict (in supervised learning).\n",
            "\n",
            "3. **Model**\n",
            "   - A model is a mathematical representation of a real-world process. It takes input features and produces an output (prediction).\n",
            "\n",
            "4. **Training and Testing**\n",
            "   - The dataset is typically split into a training set (used to train the model) and a testing set (used to evaluate its performance).\n",
            "\n",
            "5. **Loss Function**\n",
            "   - The loss function measures how well the model‚Äôs predictions match the actual labels. The goal of training is to minimize this loss.\n",
            "\n",
            "6. **Overfitting and Underfitting**\n",
            "   - Overfitting occurs when a model learns the training data too well, including its noise, and performs poorly on new data. Underfitting happens when the model is too simple to capture the underlying patterns.\n",
            "\n",
            "---\n",
            "\n",
            "**Common Machine Learning Algorithms**\n",
            "\n",
            "1. **Linear Regression**\n",
            "   - Used for predicting a continuous value. It models the relationship between input features and the output as a straight line.\n",
            "\n",
            "2. **Logistic Regression**\n",
            "   - Used for binary classification problems. It predicts the probability that an input belongs to a particular class.\n",
            "\n",
            "3. **Decision Trees**\n",
            "   - These models split the data into branches based on feature values, making decisions at each node.\n",
            "\n",
            "4. **Random Forests**\n",
            "   - An ensemble of decision trees that improves prediction accuracy by averaging the results of multiple trees.\n",
            "\n",
            "5. **Support Vector Machines (SVM)**\n",
            "   - SVMs find the optimal boundary (hyperplane) that separates different classes in the data.\n",
            "\n",
            "6. **K-Nearest Neighbors (KNN)**\n",
            "   - This algorithm classifies new data points based on the majority class among its k-nearest neighbors in the training set.\n",
            "\n",
            "7. **Neural Networks**\n",
            "   - Inspired by the human brain, neural networks consist of interconnected layers of nodes (neurons) that can model complex, non-linear relationships.\n",
            "\n",
            "8. **Clustering Algorithms (e.g., K-Means)**\n",
            "   - Used in unsupervised learning to group similar data points together.\n",
            "\n",
            "---\n",
            "\n",
            "**Applications of Machine Learning**\n",
            "\n",
            "Machine learning is ubiquitous in modern technology. Some notable applications include:\n",
            "\n",
            "- **Healthcare:** Disease diagnosis, personalized medicine, and drug discovery.\n",
            "- **Finance:** Fraud detection, algorithmic trading, and credit risk assessment.\n",
            "- **Retail:** Recommendation systems, inventory management\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import mlflow\n",
        "\n",
        "with mlflow.start_run(run_name=\"openai-llm-tracking-2\"):\n",
        "    # Enable auto-tracing for OpenAI\n",
        "    mlflow.openai.autolog()\n",
        "\n",
        "    # Initialize the OpenAI client\n",
        "    openai_client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "    # Define the messages\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\", \n",
        "            \"content\": \"You are a helpful assistant.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the concept of machine learning in 1000 words.\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Make the request and print the response\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4.1\",\n",
        "        messages=messages,\n",
        "        temperature=0.1,\n",
        "        max_tokens=1000,\n",
        "    )\n",
        "\n",
        "    print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Total token usage: ==\n",
            "  Input tokens: 29\n",
            "  Output tokens: 1000\n",
            "  Total tokens: 1029\n",
            "\n",
            "== Detailed usage for each LLM call: ==\n",
            "Completions:\n",
            "  Input tokens: 29\n",
            "  Output tokens: 1000\n",
            "  Total tokens: 1029\n"
          ]
        }
      ],
      "source": [
        "# Get the trace object just created\n",
        "# Define a function to print the token usage\n",
        "def print_token_usage(trace):\n",
        "    # Print the token usage\n",
        "    total_usage = trace.info.token_usage\n",
        "    print(\"== Total token usage: ==\")\n",
        "    print(f\"  Input tokens: {total_usage['input_tokens']}\")\n",
        "    print(f\"  Output tokens: {total_usage['output_tokens']}\")\n",
        "    print(f\"  Total tokens: {total_usage['total_tokens']}\")\n",
        "\n",
        "    # Print the token usage for each LLM call\n",
        "    print(\"\\n== Detailed usage for each LLM call: ==\")\n",
        "    for span in trace.data.spans:\n",
        "        if usage := span.get_attribute(\"mlflow.chat.tokenUsage\"):\n",
        "            print(f\"{span.name}:\")\n",
        "            print(f\"  Input tokens: {usage['input_tokens']}\")\n",
        "            print(f\"  Output tokens: {usage['output_tokens']}\")\n",
        "            print(f\"  Total tokens: {usage['total_tokens']}\")\n",
        "\n",
        "# Get the trace object just created\n",
        "last_trace_id = mlflow.get_last_active_trace_id()\n",
        "trace = mlflow.get_trace(trace_id=last_trace_id)\n",
        "print_token_usage(trace)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Google Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Machine learning (ML) is a subset of artificial intelligence (AI) that **enables computers to \"learn\" from data without being explicitly programmed.** Instead of a human programmer writing specific instructions for every possible scenario, an ML model is trained on a large dataset, allowing it to identify patterns, make predictions, and adapt its behavior based on the data it has seen.\n",
            "\n",
            "Think of it like teaching a child:\n",
            "\n",
            "*   **Traditional Programming:** You give the child a strict, step-by-step rulebook for everything they might encounter. \"If you see a red ball, call it 'ball'. If you see a blue car, call it 'car'.\"\n",
            "*   **Machine Learning:** You show the child many examples of red balls, blue cars, green trees, etc., and tell them what each one is. After seeing many examples, the child starts to figure out the general characteristics of balls, cars, and trees, and can then correctly identify new, unseen balls, cars, or trees, even if they're slightly different from the examples they saw.\n",
            "\n",
            "---\n",
            "\n",
            "### Core Concepts of Machine Learning\n",
            "\n",
            "1.  **Data is King:** ML models learn from data. The more high-quality, relevant data you feed them, the better they will learn and perform. This data can be numbers, text, images, audio, etc.\n",
            "\n",
            "2.  **Features:** These are the individual measurable properties or characteristics of the data you're using. For example, if you're predicting house prices, features might include square footage, number of bedrooms, location, and age.\n",
            "\n",
            "3.  **Model:** This is the \"brain\" or the learned representation that an ML algorithm creates during the training process. It encapsulates the patterns and relationships discovered in the data.\n",
            "\n",
            "4.  **Algorithm:** This is the specific method or set of rules the computer uses to learn from the data and build the model. Examples include linear regression, decision trees, support vector machines, neural networks, etc.\n",
            "\n",
            "5.  **Training:** This is the process where the ML algorithm is fed the data and adjusts its internal parameters to find the patterns and relationships. The goal is for the model to minimize errors in its predictions or classifications.\n",
            "\n",
            "6.  **Prediction/Inference:** Once the model is trained, it can be used to make predictions or decisions on new, unseen data.\n",
            "\n",
            "7.  **Evaluation:** After training, the model's performance is measured using metrics (e.g., accuracy, precision, recall) to determine how well it generalizes to new data.\n",
            "\n",
            "---\n",
            "\n",
            "### How Machine Learning Works (Simplified Process)\n",
            "\n",
            "1.  **Gather Data:** Collect relevant data for the problem you want to solve.\n",
            "2.  **Prepare Data:** Clean, organize, and transform the data into a format suitable for the algorithm (e.g., handling missing values, scaling features).\n",
            "3.  **Choose a Model/Algorithm:** Select an appropriate machine learning algorithm based on the type of problem (e.g., classification, regression).\n",
            "4.  **Train the Model:** Feed the prepared data to the algorithm. The algorithm learns patterns and relationships from this \"training data\" to build the model.\n",
            "5.  **Evaluate the Model:** Test the trained model on a separate set of \"test data\" (data it hasn't seen before) to assess its performance and accuracy.\n",
            "6.  **Deploy the Model:** Once satisfied with the performance, the model can be used in real-world applications to make predictions or decisions.\n",
            "7.  **Monitor and Refine:** Continuously monitor the model's performance and retrain it with new data as needed to maintain accuracy and adapt to changes.\n",
            "\n",
            "---\n",
            "\n",
            "### Types of Machine Learning\n",
            "\n",
            "There are three primary types of machine learning, categorized by how the model learns:\n",
            "\n",
            "1.  **Supervised Learning:**\n",
            "    *   **Concept:** The model learns from \"labeled data,\" meaning each training example includes both the input and the correct output (the \"answer\"). Like learning with a teacher.\n",
            "    *   **Tasks:**\n",
            "        *   **Classification:** Predicting a category or class (e.g., spam/not spam, disease/no disease, dog/cat).\n",
            "        *   **Regression:** Predicting a continuous numerical value (e.g., house prices, temperature, stock prices).\n",
            "    *   **Examples:** Image recognition, spam detection, medical diagnosis, predicting sales.\n",
            "\n",
            "2.  **Unsupervised Learning:**\n",
            "    *   **Concept:** The model learns from \"unlabeled data,\" meaning it's given only input data without any corresponding output labels. The goal is to find hidden patterns, structures, or relationships within the data on its own. Like learning without a teacher, discovering patterns.\n",
            "    *   **Tasks:**\n",
            "        *   **Clustering:** Grouping similar data points together (e.g., customer segmentation, gene sequencing).\n",
            "        *   **Dimensionality Reduction:** Reducing the number of features while retaining important information (e.g., data compression).\n",
            "        *   **Association Rule Mining:** Finding relationships between variables (e.g., \"customers who buy bread often buy milk\").\n",
            "    *   **Examples:** Recommending products, anomaly detection, data compression.\n",
            "\n",
            "3.  **Reinforcement Learning:**\n",
            "    *   **Concept:** An \"agent\" learns by interacting with an \"environment\" and receiving \"rewards\" for desired behaviors and \"penalties\" for undesired ones. The goal is to learn a policy that maximizes cumulative reward over time. Like learning by trial and error.\n",
            "    *   **Tasks:** Training agents to play games, robotic navigation, optimizing complex systems.\n",
            "    *   **Examples:** AI playing chess or Go (AlphaGo), self-driving cars, automated trading systems.\n",
            "\n",
            "---\n",
            "\n",
            "### Why is Machine Learning Important?\n",
            "\n",
            "*   **Automation of Complex Tasks:** It can automate tasks that are too complex or nuanced for traditional rule-based programming (e.g., recognizing faces in photos).\n",
            "*   **Pattern Discovery in Big Data:** It can uncover hidden insights and trends in massive datasets that would be impossible for humans to find.\n",
            "*   **Adaptability:** ML models can continuously learn and improve over time as they are exposed to new data.\n",
            "*   **Personalization:** Powers recommendation systems, personalized content delivery, and tailored user experiences.\n",
            "*   **Predictive Power:** Enables accurate predictions for various fields, from finance to healthcare.\n",
            "\n",
            "In essence, machine learning empowers computers to become smarter and more autonomous by enabling them to learn directly from experience (data), rather than relying solely on explicit instructions. This capability is transforming nearly every industry and aspect of our daily lives.\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "import os\n",
        "import google.genai as genai\n",
        "from google.genai import types\n",
        "\n",
        "with mlflow.start_run(run_name=\"gemini-llm-tracking\"):\n",
        "    # Turn on auto tracing for Gemini\n",
        "    mlflow.gemini.autolog()\n",
        "\n",
        "    # Configure the SDK with your API key.\n",
        "    client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "    # Use the generate_content method to generate responses to your prompts.\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\", \n",
        "        contents=\"Explain the concept of machine learning\"\n",
        "        # config=types.GenerateContentConfig(\n",
        "        #     temperature=0.1,\n",
        "        #     max_output_tokens=500,\n",
        "        # )\n",
        "    )\n",
        "\n",
        "    print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n",
            "1383\n"
          ]
        }
      ],
      "source": [
        "print(response.usage_metadata.prompt_token_count)\n",
        "print(response.usage_metadata.candidates_token_count)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
